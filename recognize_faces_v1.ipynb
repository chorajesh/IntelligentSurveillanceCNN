{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big Data Group I : Intelligent Surveillance -- Image Tagging Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajesh/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import errno\n",
    "import dlib\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import openface\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras.models import load_model\n",
    "from keras.models import load_model\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This function is used to create the folder if it doesn't exist\n",
    "#### If the directory already exists, don't do anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdirP(path):\n",
    "    \"\"\"\n",
    "    Create a directory and don't error if the path already exists.\n",
    "\n",
    "    If the directory already exists, don't do anything.\n",
    "\n",
    "    :param path: The directory to create.\n",
    "    :type path: str\n",
    "    \"\"\"\n",
    "    assert path is not None\n",
    "\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc:  # Python >2.5\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get all the Names from the csv file and make a dictionary of Name and the label number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNames(filePath):\n",
    "    personNameFile = pd.read_csv(filePath)\n",
    "    dict_labels={}\n",
    "    for (name, category) in zip(personNameFile['Name'] ,personNameFile['personCategory']):\n",
    "        dict_labels[category]=name\n",
    "    return dict_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the keras model which was built in the BuildCNNImgClsModel into model variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel():\n",
    "    model = load_model('./tagFaceFinalModel.keras')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the image from the path and put it into image variable after \n",
    "#### resizing to 480,480 pixels and convert the image into rgb format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readImage(imagePath):\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image,(480,480))\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image, rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the indices of the boxes for the recognized faces using face_recognition package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFaceBoxes(rgbImage):\n",
    "    boxes = face_recognition.face_locations(rgbImage,\n",
    "                                        model=\"cnn\")\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Align the faces that were identified in the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAlignedImage(faceImage, size):\n",
    "    outRgb = align.align(size, faceImage,landmarkIndices=landmarkIndices)\n",
    "    outBgr = None\n",
    "    if outRgb is not None:\n",
    "                    outBgr = cv2.cvtColor(outRgb, cv2.COLOR_RGB2BGR)\n",
    "                    #print(outBgr)\n",
    "    return outBgr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tag the faces with the names identified by the model. Draw the rectangle around the face and put the name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagTheFaces(boxIndices, sourceImage):\n",
    "    names = []\n",
    "    for ((top, right, bottom, left)) in boxIndices:\n",
    "        # draw the predicted face name on the image\n",
    "        #cv2.rectangle(image, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "        face_frames = [left, top, right, bottom]\n",
    "        face = Image.fromarray(sourceImage).crop(face_frames)\n",
    "        npFace = np.array(face)\n",
    "        alignedPic = getAlignedImage(npFace,96)\n",
    "        if alignedPic is not None:\n",
    "            gray = cv2.cvtColor(alignedPic, cv2.COLOR_BGR2GRAY)/255.0\n",
    "            train_data = np.array([gray.reshape(96, 96, 1)])\n",
    "            #print(train_data.shape)\n",
    "            maxProb = np.max(model.predict(train_data), axis=1)\n",
    "            #print(maxProb)\n",
    "            if(maxProb >=0.4):\n",
    "                name = dict_labels[int(np.argmax(model.predict(train_data), axis=1))]\n",
    "            else:\n",
    "                name = \"Unknown\"\n",
    "        else:\n",
    "            name = \"UnIdentified\"\n",
    "        #print(name)\n",
    "        names.append(name)\n",
    "    return names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the Tagged image to TagImageDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveTaggedImage(boxIndices, names, sourceImage, savePath):\n",
    "    # loop over the recognized faces\n",
    "    #print(boxIndices)\n",
    "    for ((top, right, bottom, left), name) in zip(boxIndices, names):\n",
    "        # draw the predicted face name on the image\n",
    "        cv2.rectangle(sourceImage, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "        y = top - 15 if top - 15 > 15 else top + 15\n",
    "        cv2.putText(sourceImage, name, (left, y), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.75, (0, 255, 0), 2)\n",
    "\n",
    "    # show the output image\n",
    "    cv2.imwrite(savePath,sourceImage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process the Image that were at a specific path and save the image at the path specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processImages(imagePath, savePath):\n",
    "    image,rgb = readImage(imagePath)\n",
    "    boxes = getFaceBoxes(rgb)\n",
    "    names = tagTheFaces(boxes, image)\n",
    "    saveTaggedImage(boxes, names, image, savePath)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the required parameters for aligning the faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarkMap = {\n",
    "        'outerEyesAndNose': openface.AlignDlib.OUTER_EYES_AND_NOSE,\n",
    "        'innerEyesAndBottomLip': openface.AlignDlib.INNER_EYES_AND_BOTTOM_LIP\n",
    "    }\n",
    "\n",
    "landmarkIndices = landmarkMap[\"outerEyesAndNose\"]\n",
    "\n",
    "align = openface.AlignDlib(\"./openface/models/dlib/shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "model = getModel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the Names and their label to dictionary object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_labels = getNames(\"./LFWGrayImagesWithPixels_Modified_gt10.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the input directory of images to be processed and Output Directory for the Tagged Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSetPath = \"./imageSet1/\"\n",
    "saveImageDataDir = \"./TagImageDir\"\n",
    "# Get the path of all the images from the input Image Directory path\n",
    "imageName = os.listdir(dataSetPath)\n",
    "# Create the TagImageDir\n",
    "mkdirP(saveImageDataDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterate through all the images, process, using the model identify the name, tag and save in output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./imageSet1/IMG_4959.JPG\n",
      "./imageSet1/IMG_4960.JPG\n",
      "./imageSet1/IMG_4961.JPG\n",
      "./imageSet1/IMG_4962.JPG\n"
     ]
    }
   ],
   "source": [
    "for image in imageName:\n",
    "            imageFileName  = os.path.join(dataSetPath,image)\n",
    "            print(imageFileName)\n",
    "            saveFileName = os.path.join(saveImageDataDir, image)\n",
    "            #print(saveFileName)\n",
    "            processImages(imageFileName, saveFileName)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
